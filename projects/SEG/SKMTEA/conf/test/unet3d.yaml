pretrained: true
checkpoint: None
mode: test

model:
  model_name: SEGMENTATION3DUNET
  use_reconstruction_module: false
  segmentation_module: UNet
  segmentation_module_input_channels: 1
  segmentation_module_output_channels: 4  # N + 1 (bg) channels, if multiclass segmentation
  segmentation_module_channels: 32
  segmentation_module_pooling_layers: 5
  segmentation_module_dropout: 0.0
  segmentation_module_normalize: false
  segmentation_module_norm_groups: 2
  segmentation_loss:
    binary_cross_entropy: 0.5  # if multilabel segmentation
#    categorical_cross_entropy: 0.5  # if multiclass segmentation
    dice: 0.5
  # binary_cross_entropy loss
  cross_entropy_loss_include_background: true  # for ce loss computation only -> since bg is removed during preproc in skm-tea
  cross_entropy_loss_classes_weight: [1.0, 1.0, 1.0, 1.0]
  cross_entropy_loss_reduction: mean
  # categorical_cross_entropy loss
#  cross_entropy_loss_include_background: false  # bg is removed during preproc in skm-tea, however is added back since we are doing multiclass segmentation -> so disable during metric computation
#  cross_entropy_loss_classes_weight: [1.0, 1.0, 1.0, 1.0]
#  cross_entropy_loss_to_onehot_y: false  # since it's softmaxed -> already one-hot encoded
#  cross_entropy_loss_reduction: mean
  # dice loss
  dice_loss_include_background: true  # always set to true if the background is removed -> since bg is removed during preproc in skm-tea
#  dice_loss_include_background: false  # if multiclass segmentation, bg is removed during preproc in skm-tea, however is added back since we are doing multiclass segmentation -> so disable during metric computation
  dice_loss_to_onehot_y: false
  dice_loss_sigmoid: false  # set only if segmentation_activation is not set by default to sigmoid for multilabel or softmax for multiclass, otherwise it will reapplied to already sigmoided outputs
  dice_loss_softmax: false  # set only if segmentation_activation is not set by default to sigmoid for multilabel or softmax for multiclass, otherwise it will reapplied to already softmaxed outputs
  dice_loss_other_act: none
  dice_loss_squared_pred: false
  dice_loss_jaccard: false
  dice_loss_flatten: false
  dice_loss_reduction: mean  # since dice_loss_batch is set to true, otherwise should be mean
  dice_loss_smooth_nr: 1e-5
  dice_loss_smooth_dr: 1e-5
  dice_loss_batch: true
  # binary_cross_entropy metric
  cross_entropy_metric_include_background: true  # for ce metric computation only -> since bg is removed during preproc in skm-tea
  cross_entropy_metric_classes_weight: [ 1.0, 1.0, 1.0, 1.0 ]
  cross_entropy_metric_reduction: mean
  # categorical_cross_entropy metric
#  cross_entropy_metric_include_background: false  # bg is removed during preproc in skm-tea, however is added back since we are doing multiclass segmentation -> so disable during metric computation
#  cross_entropy_metric_classes_weight: [1.0, 1.0, 1.0, 1.0]
#  cross_entropy_metric_to_onehot_y: false  # since it's softmaxed -> already one-hot encoded
#  cross_entropy_metric_reduction: mean
  dice_metric_include_background: true  # always set to true if the background is removed -> since bg is removed during preproc in skm-tea
#  dice_metric_include_background: false  # if multiclass segmentation, bg is removed during preproc in skm-tea, however is added back since we are doing multiclass segmentation -> so disable during metric computation
  dice_metric_to_onehot_y: false
  dice_metric_sigmoid: false  # set only if segmentation_activation is not set by default to sigmoid for multilabel or softmax for multiclass, otherwise it will reapplied to already sigmoided outputs
  dice_metric_softmax: false  # set only if segmentation_activation is not set by default to sigmoid for multilabel or softmax for multiclass, otherwise it will reapplied to already softmaxed outputs
  dice_metric_other_act: none
  dice_metric_squared_pred: false
  dice_metric_jaccard: false
  dice_metric_flatten: false
  dice_metric_reduction: mean  # since dice_metric_batch is set to true, otherwise should be mean
  dice_metric_smooth_nr: 1e-5
  dice_metric_smooth_dr: 1e-5
  dice_metric_batch: true
  segmentation_classes_thresholds: [0.5, 0.5, 0.5, 0.5]
  segmentation_activation: sigmoid
#  segmentation_activation: softmax  # if multiclass segmentation
#  segmentation_mode: multiclass
  magnitude_input: true
  log_multiple_modalities: false  # log all modalities in the same image, e.g. T1, T2, T1ce, FLAIR will be concatenated
  normalization_type: minmax
  normalize_segmentation_output: true
  unnormalize_loss_inputs: false
  unnormalize_log_outputs: false
  metric_computation_mode: per_slice  # per_slice: metrics are computed slice-wise and aggregated all together, per_volume: metrics are computed volume-wise and averaged by volume
  complex_data: false
  consecutive_slices: 3
  dimensionality: 3
  coil_combination_method: None
  coil_dim: None

  test_ds:
    data_path: data_parent_dir/skm-tea/v1-release/json/image_files_test.json
    coil_sensitivity_maps_path: None
    mask_path: None
    noise_path: None
    initial_predictions_path: None
    dataset_format: skm-tea-echo1
    sample_rate: 1
    volume_sample_rate: None
    use_dataset_cache: false
    dataset_cache_file: None
    num_cols: None
    consecutive_slices: 3
    data_saved_per_slice: false
    complex_target: false
    log_images_rate: 0.05
    apply_prewhitening: false
    apply_gcc: false
    estimate_coil_sensitivity_maps: false
    coil_combination_method: None
    dimensionality: 3
    mask_args:
      type: none
    partial_fourier_percentage: 0.0
    remask: false
    crop_size: None
    kspace_crop: false
    crop_before_masking: true
    kspace_zero_filling_size: None
    normalize_inputs: true
    normalization_type: minmax
    kspace_normalization: false
    coil_dim: None
    use_seed: true
    segmentations_path: None
    segmentation_classes: 4
#    segmentation_classes: 5  # N + 1 (bg) channels, if multiclass segmentation
#    segmentation_mode: multiclass
    complex_data: false
    batch_size: 1
    shuffle: false
    num_workers: 8
    pin_memory: false
    drop_last: false

  optim:
    name: adam
    lr: 1e-4
    betas:
      - 0.9
      - 0.98
    weight_decay: 0.0
    sched:
      name: InverseSquareRootAnnealing
      min_lr: 0.0
      last_epoch: -1
      warmup_ratio: 0.1

trainer:
  strategy: ddp_find_unused_parameters_false
  accelerator: gpu
  devices: 1
  num_nodes: 1
  max_epochs: 20
  precision: 16-mixed  # '16-mixed', 'bf16-mixed', '32-true', '64-true', '64', '32', '16', 'bf16'
  enable_checkpointing: false
  logger: false
  log_every_n_steps: 50
  check_val_every_n_epoch: -1
  max_steps: -1

exp_manager:
  exp_dir: output_dir/atommic/segmentation/predictions/SKMTEA/UNet3D
  ema:
    enable: false
  create_tensorboard_logger: true
  create_wandb_logger: false
